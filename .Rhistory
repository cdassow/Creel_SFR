shape = median(pars.wd25.gamma[,1]),
rate = median(pars.wd25.gamma[,2]))),
treat=c(rep("observed",length(ttrExp$total.harv[ttrExp$treat=="wd25"])),rep("pred",length(ttrExp$total.harv[ttrExp$treat=="wd25"]))))
wd50Comp.gamma=data.frame(harv.hectare=c(ttrExp$total.harv[ttrExp$treat=="wd50"],rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="wd50"]),
shape = median(pars.wd50.gamma[,1]),
rate = median(pars.wd50.gamma[,2]))),
treat=c(rep("observed",length(ttrExp$total.harv[ttrExp$treat=="wd50"])),rep("pred",length(ttrExp$total.harv[ttrExp$treat=="wd50"]))))
we50Comp.gamma=data.frame(harv.hectare=c(ttrExp$total.harv[ttrExp$treat=="we50"],rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="we50"]),
shape = median(pars.we50.gamma[,1]),
rate = median(pars.we50.gamma[,2]))),
treat=c(rep("observed",length(ttrExp$total.harv[ttrExp$treat=="we50"])),rep("pred",length(ttrExp$total.harv[ttrExp$treat=="we50"]))))
a.p.gamma=ggplot(aComp.gamma)+theme_classic()+
geom_density(aes(x=harv.hectare,fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Annual Harvest per Acre", y="Density", title = "Actual", fill=element_blank())
nw.p.gamma=ggplot(nwComp.gamma)+theme_classic()+
geom_density(aes(x=harv.hectare,fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Annual Harvest per Acre", y="Density", title = "No Winter Data \n(April - October)", fill=element_blank())
ma.p.gamma=ggplot(maComp.gamma)+theme_classic()+
geom_density(aes(x=harv.hectare,fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Annual Harvest per Acre", y="Density", title = "May - August \nData Only", fill=element_blank())
wd25.p.gamma=ggplot(wd25Comp.gamma)+theme_classic()+
geom_density(aes(x=harv.hectare,fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Annual Harvest per Acre", y="Density", title = "25% of Weekday \nCreel Visits/Month \nRemoved", fill=element_blank())
wd50.p.gamma=ggplot(wd25Comp.gamma)+theme_classic()+
geom_density(aes(x=harv.hectare,fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Annual Harvest per Acre", y="Density", title = "50% of Weekday \nCreel Visits/Month \nRemoved", fill=element_blank())
we50.p.gamma=ggplot(we50Comp.gamma)+theme_classic()+
geom_density(aes(x=harv.hectare,fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Annual Harvest per Acre", y="Density", title = "50% of Weekdend \nCreel Visits/Month \nRemoved", fill=element_blank())
ggarrange(a.p.gamma,nw.p.gamma,ma.p.gamma,wd25.p.gamma,wd50.p.gamma,we50.p.gamma, common.legend = T)
### MODEL CHECKNG ####
gelmanDiagnostics(harv.actual.gamma) # 1.01 converged
gelmanDiagnostics(harv.nw.gamma) # 1.01 converged
gelmanDiagnostics(harv.ma.gamma) # 1.01 converged
gelmanDiagnostics(harv.25wd.gamma) # 1.01 converged
gelmanDiagnostics(harv.50wd.gamma) # 1.02 converged
gelmanDiagnostics(harv.50we.gamma) # 1.01 converged
# bayesian p-value for each model
# dataframe to hold output
bpval.self.gamma=data.frame(scenario=c("Actual", "No Winter", "May-August","25% weeday removal","50% weekday removal","50% weekend removal"),
sd.pval=NA)
#### Pb ACTUAL ####
pval.actual=data.frame(shape=rep(NA,nrow(pars.a.gamma)),
rate=NA,
sd=NA)
set.seed(10)
for(i in 1:nrow(pars.a.gamma)){
tempdat=rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="actual"]),
shape = pars.a.gamma[i,1],
rate = pars.a.gamma[i,2])
pval.actual$shape[i]=pars.a.gamma[i,1]
pval.actual$rate[i]=pars.a.gamma[i,2]
pval.actual$sd[i]=sd(tempdat)
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.actual$sdExceed=0
actual.sd=sd(ttrExp$total.harv[ttrExp$treat=="actual"])
pval.actual$sdExceed[pval.actual$sd>actual.sd]=1
bpval.self.gamma$sd.pval[1]=sum(pval.actual$sdExceed==1)/nrow(pval.actual) # if this value is < 0.1 for >0.9 that would suggest model is not fitting well. 0.5 is ideal
#### Pb NO WINTER ####
pval.noWinter=data.frame(shape=rep(NA,nrow(pars.nw.gamma)),
rate=NA,
sd=NA)
set.seed(10)
for(i in 1:nrow(pars.nw.gamma)){
tempdat=rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="noWinter"]),
shape = pars.nw.gamma[i,1],
rate = pars.nw.gamma[i,2])
pval.noWinter$shape[i]=pars.nw.gamma[i,1]
pval.noWinter$rate[i]=pars.nw.gamma[i,2]
pval.noWinter$sd[i]=sd(tempdat)
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.noWinter$sdExceed=0
noWinter.sd=sd(ttrExp$total.harv[ttrExp$treat=="noWinter"])
pval.noWinter$sdExceed[pval.noWinter$sd>noWinter.sd]=1
bpval.self.gamma$sd.pval[2]=sum(pval.noWinter$sdExceed==1)/nrow(pval.noWinter) # if this value is < 0.1 for >0.9 that would suggest model is not fitting well. 0.5 is ideal
#### Pb MAYAUGUST ####
pval.mayAug=data.frame(shape=rep(NA,nrow(pars.ma.gamma)),
rate=NA,
sd=NA)
set.seed(10)
for(i in 1:nrow(pars.ma.gamma)){
tempdat=rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="mayAug"]),
shape = pars.ma.gamma[i,1],
rate = pars.ma.gamma[i,2])
pval.mayAug$shape[i]=pars.ma.gamma[i,1]
pval.mayAug$rate[i]=pars.ma.gamma[i,2]
pval.mayAug$sd[i]=sd(tempdat)
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.mayAug$sdExceed=0
mayAug.sd=sd(ttrExp$total.harv[ttrExp$treat=="mayAug"])
pval.mayAug$sdExceed[pval.mayAug$sd>mayAug.sd]=1
bpval.self.gamma$sd.pval[3]=sum(pval.mayAug$sdExceed==1)/nrow(pval.mayAug) # if this value is < 0.1 for >0.9 that would suggest model is not fitting well. 0.5 is ideal
#### Pb WD25 ####
pval.wd25=data.frame(shape=rep(NA,nrow(pars.wd25.gamma)),
rate=NA,
sd=NA)
set.seed(10)
for(i in 1:nrow(pars.wd25.gamma)){
tempdat=rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="wd25"]),
shape = pars.wd25.gamma[i,1],
rate = pars.wd25.gamma[i,2])
pval.wd25$shape[i]=pars.wd25.gamma[i,1]
pval.wd25$rate[i]=pars.wd25.gamma[i,2]
pval.wd25$sd[i]=sd(tempdat)
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.wd25$sdExceed=0
wd25.sd=sd(ttrExp$total.harv[ttrExp$treat=="wd25"])
pval.wd25$sdExceed[pval.wd25$sd>wd25.sd]=1
bpval.self.gamma$sd.pval[4]=sum(pval.wd25$sdExceed==1)/nrow(pval.wd25) # if this value is < 0.1 for >0.9 that would suggest model is not fitting well. 0.5 is ideal
#### Pb WD50 ####
pval.wd50=data.frame(shape=rep(NA,nrow(pars.wd50.gamma)),
rate=NA,
sd=NA)
set.seed(10)
for(i in 1:nrow(pars.wd50.gamma)){
tempdat=rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="wd50"]),
shape = pars.wd50.gamma[i,1],
rate = pars.wd50.gamma[i,2])
pval.wd50$shape[i]=pars.wd50.gamma[i,1]
pval.wd50$rate[i]=pars.wd50.gamma[i,2]
pval.wd50$sd[i]=sd(tempdat)
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.wd50$sdExceed=0
wd50.sd=sd(ttrExp$total.harv[ttrExp$treat=="wd50"])
pval.wd50$sdExceed[pval.wd50$sd>wd50.sd]=1
bpval.self.gamma$sd.pval[5]=sum(pval.wd50$sdExceed==1)/nrow(pval.wd50) # if this value is < 0.1 for >0.9 that would suggest model is not fitting well. 0.5 is ideal
#### Pb WE50 ####
pval.we50=data.frame(shape=rep(NA,nrow(pars.we50.gamma)),
rate=NA,
sd=NA)
set.seed(10)
for(i in 1:nrow(pars.we50.gamma)){
tempdat=rgamma(n=length(ttrExp$total.harv[ttrExp$treat=="we50"]),
shape = pars.we50.gamma[i,1],
rate = pars.we50.gamma[i,2])
pval.we50$shape[i]=pars.we50.gamma[i,1]
pval.we50$rate[i]=pars.we50.gamma[i,2]
pval.we50$sd[i]=sd(tempdat)
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.we50$sdExceed=0
we50.sd=sd(ttrExp$total.harv[ttrExp$treat=="we50"])
pval.we50$sdExceed[pval.we50$sd>we50.sd]=1
bpval.self.gamma$sd.pval[6]=sum(pval.we50$sdExceed==1)/nrow(pval.we50) # if this value is < 0.1 for >0.9 that would suggest model is not fitting well. 0.5 is ideal
kable(bpval.self.gamma, digits = 3, col.names = c("Scenario", "SD p-value"), align="lcc",caption = "Bayesian p-values for a gamma distributed model. Each p-value describes whether or not there is a significant difference between data generated by the fitted model and the actual data for that scenario. Standard devidation (SD) was the variance metric assessed here.")
# ## p-value tests comparing the scenarios to actual to show that some scenarios approximate the actual quite well.
#
# bpval.comp=data.frame(scenario=c("Actual", "No Winter", "May-August","25% weeday removal","50% weekday removal","50% weekend removal"),
#                       coef.var.pval=NA,
#                       sd.pval=NA)
# pval.actual$cvComp=0
# pval.actual$sdComp=0
# pval.actual$cvComp[pval.actual$cv>actual.cv]=1
# pval.actual$sdComp[pval.actual$sd>actual.sd]=1
#
# pval.noWinter$cvComp=0
# pval.noWinter$sdComp=0
# pval.noWinter$cvComp[pval.noWinter$cv>actual.cv]=1
# pval.noWinter$sdComp[pval.noWinter$sd>actual.sd]=1
#
# pval.mayAug$cvComp=0
# pval.mayAug$sdComp=0
# pval.mayAug$cvComp[pval.mayAug$cv>actual.cv]=1
# pval.mayAug$sdComp[pval.mayAug$sd>actual.sd]=1
#
# pval.wd25$cvComp=0
# pval.wd25$sdComp=0
# pval.wd25$cvComp[pval.wd25$cv>actual.cv]=1
# pval.wd25$sdComp[pval.wd25$sd>actual.sd]=1
#
# pval.wd50$cvComp=0
# pval.wd50$sdComp=0
# pval.wd50$cvComp[pval.wd50$cv>actual.cv]=1
# pval.wd50$sdComp[pval.wd50$sd>actual.sd]=1
#
# pval.we50$cvComp=0
# pval.we50$sdComp=0
# pval.we50$cvComp[pval.we50$cv>actual.cv]=1
# pval.we50$sdComp[pval.we50$sd>actual.sd]=1
#
# bpval.comp$coef.var.pval=c(sum(pval.actual$cvComp)/nrow(pval.actual),
#                            sum(pval.noWinter$cvComp)/nrow(pval.noWinter),
#                            sum(pval.mayAug$cvComp)/nrow(pval.mayAug),
#                            sum(pval.wd25$cvComp)/nrow(pval.wd25),
#                            sum(pval.wd50$cvComp)/nrow(pval.wd50),
#                            sum(pval.we50$cvComp)/nrow(pval.we50))
#
# bpval.comp$sd.pval=c(sum(pval.actual$sdComp)/nrow(pval.actual),
#                      sum(pval.noWinter$sdComp)/nrow(pval.noWinter),
#                      sum(pval.mayAug$sdComp)/nrow(pval.mayAug),
#                      sum(pval.wd25$sdComp)/nrow(pval.wd25),
#                      sum(pval.wd50$sdComp)/nrow(pval.wd50),
#                      sum(pval.we50$sdComp)/nrow(pval.we50))
#
# kable(bpval.comp, digits = 3, col.names = c("Scenario", "CV p-value","SD p-value"), align="lcc",caption = "Bayesian p-values for a rate distributed model. Each p-value describes whether or not there is a significant difference between data generated by the fitted model and the actual data for that scenario. Two metrics are assessed here, coefficient of variation (CV) and standard devidation (SD).")
# bayesian p-value for each model
pars.a=getSample(harv.actual)
pars.nw=getSample(harv.nw)
pars.ma=getSample(harv.ma)
pars.wd25=getSample(harv.25wd)
pars.wd50=getSample(harv.50wd)
pars.we50=getSample(harv.50we)
#### Pb ACTUAL ####
pval.actual=data.frame(alpha=rep(NA,nrow(pars.a)),
beta=NA,
sd=NA,
med=NA,
kurt=NA,
x2=NA,
f=NA,
lcl=NA,
ucl=NA)
set.seed(10)
for(i in 1:nrow(pars.a)){
tempdat=rlnorm(n=length(modDat$total.harv[modDat$treat=="actual"]),
meanlog = pars.a[i,1],
sdlog = pars.a[i,2])
pval.actual$alpha[i]=pars.a[i,1]
pval.actual$beta[i]=pars.a[i,2]
pval.actual$sd[i]=sd(log(tempdat))
pval.actual$med[i]=median(log(tempdat))
pval.actual$kurt[i]=kurtosis(log(tempdat))
ct=chisq.test(tempdat, p=modDat$total.harv[modDat$treat=="actual"], rescale.p = T)
pval.actual$x2[i]=ct$p.value
f.test=var.test(log(tempdat),log(modDat$total.harv[modDat$treat=="actual"]))
pval.actual$f[i]=f.test$statistic
cis=quantile(log(tempdat), probs=c(0.025, 0.975))
pval.actual$lcl[i]=cis[1]
pval.actual$ucl[i]=cis[2]
}
# now calculate the number of times the test statistic exceeds that of the real data
pval.actual$sdExceed=0
pval.actual$medExceed=0
pval.actual$kurtExceed=0
pval.actual$x2SigDiff=0
pval.actual$fStatExceed=0
pval.actual$coverageExceed=0
actual.sd=sd(log(modDat$total.harv[modDat$treat=="actual"]))
actual.med=median(log(modDat$total.harv[modDat$treat=="actual"]))
actual.kurt=kurtosis(log(modDat$total.harv[modDat$treat=="actual"]))
actual.x2=chisq.test(modDat$total.harv[modDat$treat=="actual"],p=modDat$total.harv[modDat$treat=="actual"],rescale.p = T)
actual.f=var.test(log(modDat$total.harv[modDat$treat=="actual"]),log(modDat$total.harv[modDat$treat=="actual"]))
pval.actual$sdExceed[pval.actual$sd>actual.sd]=1
pval.actual$medExceed[pval.actual$med>actual.med]=1
pval.actual$kurtExceed[pval.actual$kurt>actual.kurt]=1 # kurt value great that observed data means there are more outliers, or thicker tails than the observed data
pval.actual$x2SigDiff[pval.actual$x2<0.05]=1 # looking at how often we would say the simmed data did not come from the probability distribution of the actual data
pval.actual$fStatExceed[pval.actual$f>actual.f$statistic]=1 # how often the f statistic is bigger than the actual
pval.actual$coverageExceed[pval.actual$lcl<=mean(log(modDat$total.harv[modDat$treat=="actual"])) & pval.actual$ucl>=mean(log(modDat$total.harv[modDat$treat=="actual"]))]=1 # how often the cis from the temp data contain the mean of the actual data
#### Pb NoWinter ####
pval.noWinter=data.frame(alpha=rep(NA,nrow(pars.nw)),
beta=NA,
sd=NA,
med=NA,
kurt=NA,
x2=NA,
f=NA,
lcl=NA,
ucl=NA)
set.seed(10)
for(i in 1:nrow(pars.nw)){
tempdat=rlnorm(n=length(modDat$total.harv[modDat$treat=="noWinter"]),
meanlog = pars.nw[i,1],
sdlog = pars.nw[i,2])
pval.noWinter$alpha[i]=pars.nw[i,1]
pval.noWinter$beta[i]=pars.nw[i,2]
pval.noWinter$sd[i]=sd(log(tempdat))
pval.noWinter$med[i]=median(log(tempdat))
pval.noWinter$kurt[i]=kurtosis(log(tempdat))
ct=chisq.test(tempdat, p=modDat$total.harv[modDat$treat=="noWinter"], rescale.p = T)
pval.noWinter$x2[i]=ct$p.value
f.test=var.test(log(tempdat),log(modDat$total.harv[modDat$treat=="noWinter"]))
pval.noWinter$f[i]=f.test$statistic
cis=quantile(log(tempdat), probs=c(0.025, 0.975))
pval.noWinter$lcl[i]=cis[1]
pval.noWinter$ucl[i]=cis[2]
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.noWinter$sdExceed=0
pval.noWinter$medExceed=0
pval.noWinter$kurtExceed=0
pval.noWinter$x2SigDiff=0
pval.noWinter$fStatExceed=0
pval.noWinter$coverageExceed=0
noWinter.sd=sd(log(modDat$total.harv[modDat$treat=="noWinter"]))
noWinter.med=median(log(modDat$total.harv[modDat$treat=="noWinter"]))
noWinter.kurt=kurtosis(log(modDat$total.harv[modDat$treat=="noWinter"]))
noWinter.x2=chisq.test(modDat$total.harv[modDat$treat=="noWinter"],p=modDat$total.harv[modDat$treat=="noWinter"],rescale.p = T)
noWinter.f=var.test(log(modDat$total.harv[modDat$treat=="noWinter"]),log(modDat$total.harv[modDat$treat=="noWinter"]))
pval.noWinter$sdExceed[pval.noWinter$sd>noWinter.sd]=1
pval.noWinter$medExceed[pval.noWinter$med>noWinter.med]=1
pval.noWinter$kurtExceed[pval.noWinter$kurt>noWinter.kurt]=1 # kurt value great that observed data means there are more outliers, or thicker tails than the observed data
pval.noWinter$x2SigDiff[pval.noWinter$x2<0.05]=1 # looking at how often we would say the simmed data did not come from the probabilit distribution of the noWinter data
pval.noWinter$fStatExceed[pval.noWinter$f>noWinter.f$statistic]=1 # how often the f statistic is bigger than the noWinter
pval.noWinter$coverageExceed[pval.noWinter$lcl<=mean(log(modDat$total.harv[modDat$treat=="noWinter"])) & pval.noWinter$ucl>=mean(log(modDat$total.harv[modDat$treat=="noWinter"]))]=1 # how often the cis from the temp data contain the mean of the noWinter data
#### Pb MayAug ####
pval.mayAug=data.frame(alpha=rep(NA,nrow(pars.ma)),
beta=NA,
sd=NA,
med=NA,
kurt=NA,
x2=NA,
f=NA,
lcl=NA,
ucl=NA)
set.seed(10)
for(i in 1:nrow(pars.ma)){
tempdat=rlnorm(n=length(modDat$total.harv[modDat$treat=="mayAug"]),
meanlog = pars.ma[i,1],
sdlog = pars.ma[i,2])
pval.mayAug$alpha[i]=pars.ma[i,1]
pval.mayAug$beta[i]=pars.ma[i,2]
pval.mayAug$sd[i]=sd(log(tempdat))
pval.mayAug$med[i]=median(log(tempdat))
pval.mayAug$kurt[i]=kurtosis(log(tempdat))
ct=chisq.test(tempdat, p=modDat$total.harv[modDat$treat=="mayAug"], rescale.p = T)
pval.mayAug$x2[i]=ct$p.value
f.test=var.test(log(tempdat),log(modDat$total.harv[modDat$treat=="mayAug"]))
pval.mayAug$f[i]=f.test$statistic
cis=quantile(log(tempdat), probs=c(0.025, 0.975))
pval.mayAug$lcl[i]=cis[1]
pval.mayAug$ucl[i]=cis[2]
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.mayAug$sdExceed=0
pval.mayAug$medExceed=0
pval.mayAug$kurtExceed=0
pval.mayAug$x2SigDiff=0
pval.mayAug$fStatExceed=0
pval.mayAug$coverageExceed=0
mayAug.sd=sd(log(modDat$total.harv[modDat$treat=="mayAug"]))
mayAug.med=median(log(modDat$total.harv[modDat$treat=="mayAug"]))
mayAug.kurt=kurtosis(log(modDat$total.harv[modDat$treat=="mayAug"]))
mayAug.x2=chisq.test(modDat$total.harv[modDat$treat=="mayAug"],p=modDat$total.harv[modDat$treat=="mayAug"],rescale.p = T)
mayAug.f=var.test(log(modDat$total.harv[modDat$treat=="mayAug"]),log(modDat$total.harv[modDat$treat=="mayAug"]))
pval.mayAug$sdExceed[pval.mayAug$sd>mayAug.sd]=1
pval.mayAug$medExceed[pval.mayAug$med>mayAug.med]=1
pval.mayAug$kurtExceed[pval.mayAug$kurt>mayAug.kurt]=1 # kurt value great that observed data means there are more outliers, or thicker tails than the observed data
pval.mayAug$x2SigDiff[pval.mayAug$x2<0.05]=1 # looking at how often we would say the simmed data did not come from the probabilit distribution of the mayAug data
pval.mayAug$fStatExceed[pval.mayAug$f>mayAug.f$statistic]=1 # how often the f statistic is bigger than the mayAug
pval.mayAug$coverageExceed[pval.mayAug$lcl<=mean(log(modDat$total.harv[modDat$treat=="mayAug"])) & pval.mayAug$ucl>=mean(log(modDat$total.harv[modDat$treat=="mayAug"]))]=1 # how often the cis from the temp data contain the mean of the mayAug data
#### Pb WD25 ####
pval.wd25=data.frame(alpha=rep(NA,nrow(pars.wd25)),
beta=NA,
sd=NA,
med=NA,
kurt=NA,
x2=NA,
f=NA,
lcl=NA,
ucl=NA)
set.seed(10)
for(i in 1:nrow(pars.wd25)){
tempdat=rlnorm(n=length(modDat$total.harv[modDat$treat=="wd25"]),
meanlog = pars.wd25[i,1],
sdlog = pars.wd25[i,2])
pval.wd25$alpha[i]=pars.wd25[i,1]
pval.wd25$beta[i]=pars.wd25[i,2]
pval.wd25$sd[i]=sd(log(tempdat))
pval.wd25$med[i]=median(log(tempdat))
pval.wd25$kurt[i]=kurtosis(log(tempdat))
ct=chisq.test(tempdat, p=modDat$total.harv[modDat$treat=="wd25"], rescale.p = T)
pval.wd25$x2[i]=ct$p.value
f.test=var.test(log(tempdat),log(modDat$total.harv[modDat$treat=="wd25"]))
pval.wd25$f[i]=f.test$statistic
cis=quantile(log(tempdat), probs=c(0.025, 0.975))
pval.wd25$lcl[i]=cis[1]
pval.wd25$ucl[i]=cis[2]
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.wd25$sdExceed=0
pval.wd25$medExceed=0
pval.wd25$kurtExceed=0
pval.wd25$x2SigDiff=0
pval.wd25$fStatExceed=0
pval.wd25$coverageExceed=0
wd25.sd=sd(log(modDat$total.harv[modDat$treat=="wd25"]))
wd25.med=median(log(modDat$total.harv[modDat$treat=="wd25"]))
wd25.kurt=kurtosis(log(modDat$total.harv[modDat$treat=="wd25"]))
wd25.x2=chisq.test(modDat$total.harv[modDat$treat=="wd25"],p=modDat$total.harv[modDat$treat=="wd25"],rescale.p = T)
wd25.f=var.test(log(modDat$total.harv[modDat$treat=="wd25"]),log(modDat$total.harv[modDat$treat=="wd25"]))
pval.wd25$sdExceed[pval.wd25$sd>wd25.sd]=1
pval.wd25$medExceed[pval.wd25$med>wd25.med]=1
pval.wd25$kurtExceed[pval.wd25$kurt>wd25.kurt]=1 # kurt value great that observed data means there are more outliers, or thicker tails than the observed data
pval.wd25$x2SigDiff[pval.wd25$x2<0.05]=1 # looking at how often we would say the simmed data did not come from the probabilit distribution of the wd25 data
pval.wd25$fStatExceed[pval.wd25$f>wd25.f$statistic]=1 # how often the f statistic is bigger than the wd25
pval.wd25$coverageExceed[pval.wd25$lcl<=mean(log(modDat$total.harv[modDat$treat=="wd25"])) & pval.wd25$ucl>=mean(log(modDat$total.harv[modDat$treat=="wd25"]))]=1 # how often the cis from the temp data contain the mean of the wd25 data
#### Pb WD50 ####
pval.wd50=data.frame(alpha=rep(NA,nrow(pars.wd50)),
beta=NA,
sd=NA,
med=NA,
kurt=NA,
x2=NA,
f=NA,
lcl=NA,
ucl=NA)
set.seed(10)
for(i in 1:nrow(pars.wd50)){
tempdat=rlnorm(n=length(modDat$total.harv[modDat$treat=="wd50"]),
meanlog = pars.wd50[i,1],
sdlog = pars.wd50[i,2])
pval.wd50$alpha[i]=pars.wd50[i,1]
pval.wd50$beta[i]=pars.wd50[i,2]
pval.wd50$sd[i]=sd(log(tempdat))
pval.wd50$med[i]=median(log(tempdat))
pval.wd50$kurt[i]=kurtosis(log(tempdat))
ct=chisq.test(tempdat, p=modDat$total.harv[modDat$treat=="wd50"], rescale.p = T)
pval.wd50$x2[i]=ct$p.value
f.test=var.test(log(tempdat),log(modDat$total.harv[modDat$treat=="wd50"]))
pval.wd50$f[i]=f.test$statistic
cis=quantile(log(tempdat), probs=c(0.025, 0.975))
pval.wd50$lcl[i]=cis[1]
pval.wd50$ucl[i]=cis[2]
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.wd50$sdExceed=0
pval.wd50$medExceed=0
pval.wd50$kurtExceed=0
pval.wd50$x2SigDiff=0
pval.wd50$fStatExceed=0
pval.wd50$coverageExceed=0
wd50.sd=sd(log(modDat$total.harv[modDat$treat=="wd50"]))
wd50.med=median(log(modDat$total.harv[modDat$treat=="wd50"]))
wd50.kurt=kurtosis(log(modDat$total.harv[modDat$treat=="wd50"]))
wd50.x2=chisq.test(modDat$total.harv[modDat$treat=="wd50"],p=modDat$total.harv[modDat$treat=="wd50"],rescale.p = T)
wd50.f=var.test(log(modDat$total.harv[modDat$treat=="wd50"]),log(modDat$total.harv[modDat$treat=="wd50"]))
pval.wd50$sdExceed[pval.wd50$sd>wd50.sd]=1
pval.wd50$medExceed[pval.wd50$med>wd50.med]=1
pval.wd50$kurtExceed[pval.wd50$kurt>wd50.kurt]=1 # kurt value great that observed data means there are more outliers, or thicker tails than the observed data
pval.wd50$x2SigDiff[pval.wd50$x2<0.05]=1 # looking at how often we would say the simmed data did not come from the probabilit distribution of the wd50 data
pval.wd50$fStatExceed[pval.wd50$f>wd50.f$statistic]=1 # how often the f statistic is bigger than the wd50
pval.wd50$coverageExceed[pval.wd50$lcl<=mean(log(modDat$total.harv[modDat$treat=="wd50"])) & pval.wd50$ucl>=mean(log(modDat$total.harv[modDat$treat=="wd50"]))]=1 # how often the cis from the temp data contain the mean of the wd50 data
#### Pb WE50 ####
pval.we50=data.frame(alpha=rep(NA,nrow(pars.we50)),
beta=NA,
sd=NA,
med=NA,
kurt=NA,
x2=NA,
f=NA,
lcl=NA,
ucl=NA)
set.seed(10)
for(i in 1:nrow(pars.we50)){
tempdat=rlnorm(n=length(modDat$total.harv[modDat$treat=="we50"]),
meanlog = pars.we50[i,1],
sdlog = pars.we50[i,2])
pval.we50$alpha[i]=pars.we50[i,1]
pval.we50$beta[i]=pars.we50[i,2]
pval.we50$sd[i]=sd(log(tempdat))
pval.we50$med[i]=median(log(tempdat))
pval.we50$kurt[i]=kurtosis(log(tempdat))
ct=chisq.test(tempdat, p=modDat$total.harv[modDat$treat=="we50"], rescale.p = T)
pval.we50$x2[i]=ct$p.value
f.test=var.test(log(tempdat),log(modDat$total.harv[modDat$treat=="we50"]))
pval.we50$f[i]=f.test$statistic
cis=quantile(log(tempdat), probs=c(0.025, 0.975))
pval.we50$lcl[i]=cis[1]
pval.we50$ucl[i]=cis[2]
}
# now calculate the number of times the cv or sd exceeds that of the real data
pval.we50$sdExceed=0
pval.we50$medExceed=0
pval.we50$kurtExceed=0
pval.we50$x2SigDiff=0
pval.we50$fStatExceed=0
pval.we50$coverageExceed=0
we50.sd=sd(log(modDat$total.harv[modDat$treat=="we50"]))
we50.med=median(log(modDat$total.harv[modDat$treat=="we50"]))
we50.kurt=kurtosis(log(modDat$total.harv[modDat$treat=="we50"]))
we50.x2=chisq.test(modDat$total.harv[modDat$treat=="we50"],p=modDat$total.harv[modDat$treat=="we50"],rescale.p = T)
we50.f=var.test(log(modDat$total.harv[modDat$treat=="we50"]),log(modDat$total.harv[modDat$treat=="we50"]))
pval.we50$sdExceed[pval.we50$sd>we50.sd]=1
pval.we50$medExceed[pval.we50$med>we50.med]=1
pval.we50$kurtExceed[pval.we50$kurt>we50.kurt]=1 # kurt value great that observed data means there are more outliers, or thicker tails than the observed data
pval.we50$x2SigDiff[pval.we50$x2<0.05]=1 # looking at how often we would say the simmed data did not come from the probabilit distribution of the we50 data
pval.we50$fStatExceed[pval.we50$f>we50.f$statistic]=1 # how often the f statistic is bigger than the we50
pval.we50$coverageExceed[pval.we50$lcl<=mean(log(modDat$total.harv[modDat$treat=="we50"])) & pval.we50$ucl>=mean(log(modDat$total.harv[modDat$treat=="we50"]))]=1 # how often the cis from the temp data contain the mean of the we50 data
# the following will all be 1 if all parm values in the chain produce data with a CI that covers the mean from the actual creel data.
(sum(pval.actual$coverageExceed)/nrow(pval.actual))*100
(sum(pval.noWinter$coverageExceed)/nrow(pval.noWinter))*100
(sum(pval.mayAug$coverageExceed)/nrow(pval.mayAug))*100
(sum(pval.wd25$coverageExceed)/nrow(pval.wd25))*100
(sum(pval.wd50$coverageExceed)/nrow(pval.wd50))*100
(sum(pval.we50$coverageExceed)/nrow(pval.we50))*100
### summarizing pvalue output
# reminder this is all comparison to self
# making a list object with all the pval objects
self.pvals=list(pval.actual, pval.noWinter, pval.mayAug, pval.wd25, pval.wd50, pval.we50)
all.self.pvals=data.frame(dataSet=c(rep("actual",5),rep("noWinter",5),rep("mayAug",5),rep("wd25",5),rep("wd50",5),rep("we50",5)),
measure=rep(c("sd","med","kurt","x2Sig","f"),6),
pval=NA)
for(i in 1:length(self.pvals)){
tp=self.pvals[[i]]
datSet=unique(all.self.pvals$dataSet)[i]
all.self.pvals$pval[all.self.pvals$dataSet==datSet & all.self.pvals$measure=="sd"]=sum(tp$sdExceed==1)/nrow(tp)
all.self.pvals$pval[all.self.pvals$dataSet==datSet & all.self.pvals$measure=="med"]=sum(tp$medExceed==1)/nrow(tp)
all.self.pvals$pval[all.self.pvals$dataSet==datSet & all.self.pvals$measure=="kurt"]=sum(tp$kurtExceed==1)/nrow(tp)
all.self.pvals$pval[all.self.pvals$dataSet==datSet & all.self.pvals$measure=="x2Sig"]=sum(tp$x2SigDiff==1)/nrow(tp)
all.self.pvals$pval[all.self.pvals$dataSet==datSet & all.self.pvals$measure=="f"]=sum(tp$fStatExceed==1)/nrow(tp)
}
# not including x2 for this plot since I'm using the calculation differently. Thow shows kurtosis as the only pval metric that is markedly different from the rest
ggplot(all.self.pvals[all.self.pvals$measure!="x2Sig",])+theme_classic()+
geom_point(aes(x=measure, y=pval), size=2)+facet_wrap(~dataSet)+
geom_hline(yintercept = c(0.1,0.9), linetype=2)+
geom_hline(yintercept = 0.5, linetype=4)+
labs(y="Bayesian p-value", x="Metric")
