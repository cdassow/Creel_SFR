# length distributions of fish caught through time
ggplot(fd)+theme_classic()+
geom_histogram(aes(x=length,fill=as.factor(year)),alpha=0.2)+
scale_fill_viridis_d()+
labs(x='Length (in)',y='Number Caught',fill='Year')+
facet_wrap(species~year,scales = 'free')
msk=ggplot(fd[fd$species=='muskellunge',])+theme_classic()+
geom_histogram(aes(x=length,fill=as.factor(year)))+
scale_fill_viridis_d(option = 'turbo')+
labs(x='Length (in)',y='Number Caught',fill='Year')+
facet_wrap(~year,ncol = 1)
msk
npk=ggplot(fd[fd$species=='northern_pike',])+theme_classic()+
geom_histogram(aes(x=length,fill=as.factor(year)))+
scale_fill_viridis_d(option = 'turbo')+
labs(x='Length (in)',y='Number Caught',fill='Year')+
facet_wrap(~year,ncol = 1)
ggplot(yrCPEs)+theme_bw()+
geom_pointrange(aes(x=year,y=avgCPE,ymin=avgCPE-sdCPE,ymax=avgCPE+sdCPE))+
geom_line(aes(x=year,y=avgCPE))+
scale_x_continuous(breaks = seq(2005,2025,by=2))+
theme(axis.text.x = element_text(angle = -45,hjust = 0))+
labs(x='Year',y='Average Catch Rate')+
facet_grid(species~cpe_units,scales = 'free_y')
npk
lmb=ggplot(fd[fd$species=='largemouth_bass',])+theme_classic()+
geom_histogram(aes(x=length,fill=as.factor(year)))+
scale_fill_viridis_d(option = 'turbo')+
labs(x='Length (in)',y='Number Caught',fill='Year')+
facet_wrap(~year,ncol = 1)
lmb
View(magp)
View(mc)
yrCPEs=cpes%>%
filter(species%in%c('muskellunge','northern_pike','largemouth_bass'))%>%
group_by(year,gear,species,cpe_type,cpe_units)%>%
summarise(avgCPE=mean(cpe),
sdCPE=sd(cpe))
ggplot(yrCPEs)+theme_bw()+
geom_pointrange(aes(x=year,y=avgCPE,ymin=avgCPE-sdCPE,ymax=avgCPE+sdCPE))+
geom_line(aes(x=year,y=avgCPE))+
scale_x_continuous(breaks = seq(2005,2025,by=2))+
theme(axis.text.x = element_text(angle = -45,hjust = 0))+
labs(x='Year',y='Average Catch Rate')+
facet_grid(species~cpe_units,scales = 'free_y')
lmb=ggplot(fd[fd$species=='largemouth_bass',])+theme_classic()+
geom_histogram(aes(x=length,fill=as.factor(year)))+
scale_fill_viridis_d(option = 'turbo')+
labs(x='Length (in)',y='Number Caught',fill='Year')+
facet_wrap(~year,ncol = 1)
lmb
npk
msk
lmb
npk
ggplot(yrCPEs)+theme_bw()+
geom_pointrange(aes(x=year,y=avgCPE,ymin=avgCPE-sdCPE,ymax=avgCPE+sdCPE))+
geom_line(aes(x=year,y=avgCPE))+
scale_x_continuous(breaks = seq(2005,2025,by=2))+
theme(axis.text.x = element_text(angle = -45,hjust = 0))+
labs(x='Year',y='Average Catch Rate')+
facet_grid(species~cpe_units,scales = 'free_y')
rm(list=ls())
library(wdnr.fmdb)
library(tidyverse)
library(ggpubr)
library(lubridate)
library(BayesianTools)
setwd("C:/Users/dassocju/Documents/OAS_git_repos/Creel_SFR")
# reading in DNR creel data
# cserv=get_creel_surveys()
# cvis=get_creel_visits()
# ccou=get_creel_counts()
# cint=get_creel_int_party()
# cfish=get_creel_fish_data()
# cfish.i=get_creel_fishlen_data()
# saving all these together since they take a long time to load
# saveRDS(list(cserv,cvis,ccou,cint,cfish,cfish.i),"creelDataSet_all.RData")
call=readRDS("creelDataSet_all.RData")
# unlist, etc. to get back to individual dfs
cserv=call[[1]]
cvis=call[[2]]
ccou=call[[3]]
cint=call[[4]]
cfish=call[[5]]
cfish.i=call[[6]]
# crYear=cserv%>%
#   group_by(year)%>%
#   filter(wbic%in%ctwiWBIC.creel)%>%
#   summarize(nsurvs=length(unique(survey.seq.no)))
#
# ggplot(crYear)+
#   geom_col(aes(x=year, y=nsurvs))
## playing with built in functions first
ceff=calc_creel_effort(creel_count_data=ccou,creel_int_data=cint) # don't use the grouping argument here, seems to break it
charv=calc_creel_harvest(creel_count_data = ccou,creel_int_data = cint,creel_fish_data = cfish) # don't use the grouping argument here, seems to break it
charvR=calc_creel_harvest_rates(cfish)
#
# #empty dfs to hold output
# ttrEff=as.data.frame(matrix(NA,nrow=1,ncol=ncol(ceff)))
# colnames(ttrEff)=colnames(ceff)
# ttrEff$pReduc=NA
#
# ttrHarv=as.data.frame(matrix(NA,nrow=1,ncol = ncol(charv)))
# colnames(ttrHarv)=colnames(charv)
# ttrHarv$pReduc=NA
#
# ttrHarvR=as.data.frame(matrix(NA,nrow = 1,ncol = ncol(charvR)))
# colnames(ttrHarvR)=colnames(charvR)
# ttrHarvR$pReduc=NA
#
# pRemove=seq(0.1,0.8, by=0.1) # percent of data to remove at each loop
# survs=unique(ccou$survey.seq.no) # unqiue surveys to remove a percentage of data from (corresponds to a unique lake-year that was creeled)
#
# set.seed(2)
# for(r in 1:length(pRemove)){
#   for(i in 1:length(survs)){
#
#     # reducing data size
#     full=ccou[ccou$survey.seq.no==survs[i],]
#     reduc=full[-c(runif(n=round(nrow(full)*pRemove[r]),min = 1,max=nrow(full))),]
#
#     full.int=cint[cint$survey.seq.no==survs[i],]
#     reduc.int=full.int[-c(runif(n=round(nrow(full.int)*pRemove[r]),min = 1,max = nrow(full.int))),]
#     #removed.int=full.int[!(do.call(paste0,full.int)%in%do.call(paste0,reduc.int)),]
#
#     full.harv=cfish[cfish$survey.seq.no==survs[i],]
#     reduc.harv=full.harv[full.harv$int.party.seq.no%in%reduc.int$int.party.seq.no,] # removing all fish data associated with the removed interview data
#
#     #calculating creel stats
#     teff=calc_creel_effort(creel_count_data = reduc,creel_int_data = reduc.int)
#     tharv=calc_creel_harvest(creel_count_data = reduc,creel_int_data = reduc.int,creel_fish_data = reduc.harv)
#     tharvR=calc_creel_harvest_rates(reduc.harv)
#
#
#   # adding data to output dataframes
#     addEff=cbind(teff,pReduc=rep(pRemove[r],nrow(teff)));colnames(addEff)=colnames(ttrEff)
#     addHarv=cbind(tharv,pReduc=rep(pRemove[r],nrow(tharv)));colnames(addHarv)=colnames(ttrHarv)
#     addHarvR=cbind(tharvR,pReduc=rep(pRemove[r],nrow(tharvR)));colnames(addHarvR)=colnames(ttrHarvR)
#
#     ttrEff=rbind(ttrEff,addEff)
#     ttrHarv=rbind(ttrHarv,addHarv)
#     ttrHarvR=rbind(ttrHarvR,addHarvR)
#
#   }
# }
#
# saveRDS(list(ttrEff,ttrHarv,ttrHarvR),"titrationOutput.RData")
ttrList=readRDS("titrationOutput.RData")
ttrEff=ttrList[[1]];ttrEff=ttrEff[!is.na(ttrEff$wbic),]
ttrHarv=ttrList[[2]];ttrHarv=ttrHarv[!is.na(ttrHarv$wbic),]
ttrHarvR=ttrList[[3]];ttrHarvR=ttrHarvR[!is.na(ttrHarvR),]
# Effort titration
# looking at just one lake to begin with so I can understand the data better
wbic=ttrEff[ttrEff$wbic==ttrEff$wbic[2] & !is.na(ttrEff$month),]
actual=ceff[ceff$wbic==unique(wbic$wbic) & !is.na(ceff$month),]
# ggplot(wbic)+theme_classic()+
#   geom_line(aes(x=pReduc,y=total.effort,color=daytype))+
#   geom_line(aes(x=pReduc,y=total.effort+total.effort.sd, color=daytype),linetype=2)+
#   geom_line(aes(x=pReduc,y=total.effort-total.effort.sd, color=daytype),linetype=2)+
#   facet_wrap(~month,scales = "free_y")+
#   labs(x="% of Data Removed",y="Total Monthly Effort +/- 1 SD")
ggplot(wbic[wbic$year==2006,])+theme_classic()+
geom_pointrange(aes(x=pReduc,y=total.effort,ymax=total.effort+total.effort.sd,ymin=total.effort-total.effort.sd, color=daytype))+
geom_line(aes(x=pReduc,y=total.effort,color=daytype))+
geom_hline(data=actual,aes(yintercept = total.effort, color=daytype))+
facet_wrap(~month,scales = "free_y")+
labs(x="% of Data Removed",y="Total Monthly Effort +/- 1 SD")
ggplot(wbic)+theme_classic()+
geom_col(aes(y=total.effort,x=daytype,fill=as.character(month)),position = "stack")+
labs(x="",y="Total Effort",fill="Month")
# good, useful plots above, now how to scale this up to many lakes?
# I'm going to make a summary dataframe and a loop to go through each creel-year and pull out when the lost in accuracy occurs for each month and day type
survs=unique(ttrEff$survey.seq.no[!is.na(ttrEff$survey.seq.no)])
thresh=data.frame(wbic=NA,
year=NA,
month=NA,
daytype=NA,
survey.seq.no=NA,
actualEff=NA,
reducedEff=NA,
reducedEff.sd=NA,
pReduc=NA)
for(i in 1:length(survs)){
tdat=ttrEff[ttrEff$survey.seq.no==survs[i],]
adat=ceff[ceff$survey.seq.no==survs[i],]
for(y in 1:length(unique(adat$year))){
for(m in 1:length(unique(adat$month))){
for(d in 1:length(unique(adat$daytype))){
z=tdat[tdat$year==unique(adat$year)[y] & tdat$month==unique(adat$month)[m] & tdat$daytype==unique(adat$daytype)[d],]
b=adat[adat$year==unique(adat$year)[y] & adat$month==unique(adat$month)[m] & adat$daytype==unique(adat$daytype)[d],]
if(any(unique(z$total.effort)!=0)){
pR=max(unique(z$pReduc)[which(!(b$total.effort<(z$total.effort+z$total.effort.sd) & b$total.effort>(z$total.effort-z$total.effort.sd)))])
if(is.infinite(pR)){
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
actualEff=b$total.effort,
reducedEff=NA,
reducedEff.sd=NA,
pReduc=NA)
thresh=rbind(thresh,addDat)
}else{
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
actualEff=b$total.effort,
reducedEff=z$total.effort[z$pReduc==pR],
reducedEff.sd=z$total.effort.sd[z$pReduc==pR],
pReduc=pR)
thresh=rbind(thresh,addDat)
}
}
}
}
}
}
thresh=thresh[!is.na(thresh$wbic),]
# warnings about -inf are fine and dealt with in t he loop using the is.infinite() call
ggplot(thresh)+theme_classic()+
geom_bar(aes(x=pReduc,fill=daytype),position = "dodge")+
facet_wrap(~month, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Day Type")+
theme(legend.position = "bottom")
# grouping across month
annualThresh=thresh%>%
group_by(wbic,year,daytype, survey.seq.no)%>%
summarise(actualEff=sum(as.numeric(actualEff)),
reducedEff=sum(as.numeric(reducedEff),na.rm = T),
reducedEff.sd=sd(as.numeric(reducedEff),na.rm = T),
meanPR=mean(as.numeric(pReduc),na.rm=T))
ggplot(annualThresh)+theme_classic()+
geom_density(aes(x=meanPR,fill=daytype),alpha=0.2)
# consider at some point doing something similar to the 'thresh' loop and calculating % diff between the effort estimate at each pReduce and the true estimate % diff = ((reduced-actual)/actual)*100. Then you could plot pReduce by % diff and start building that curve we talked about at the meeting.
# threshold loop for catch
survs=unique(ttrHarv$survey.seq.no[!is.na(ttrHarv$survey.seq.no)])
thresh.c=data.frame(wbic=NA,
year=NA,
month=NA,
daytype=NA,
survey.seq.no=NA,
species=NA,
actual.catch.rate=NA,
reduced.catch.rate=NA,
reduced.catch.rate.sd=NA,
pReduc=NA)
for(i in 1:length(survs)){
tdat=ttrHarv[ttrHarv$survey.seq.no==survs[i],]
adat=charv[charv$survey.seq.no==survs[i],]
for(y in 1:length(unique(adat$year))){
for(m in 1:length(unique(adat$month))){
for(d in 1:length(unique(adat$daytype))){
for(s in 1:length(unique(adat$species))){
z=tdat[tdat$year==unique(adat$year)[y] &
tdat$month==unique(adat$month)[m] &
tdat$daytype==unique(adat$daytype)[d] &
tdat$species==unique(adat$species)[s],]
b=adat[adat$year==unique(adat$year)[y] &
adat$month==unique(adat$month)[m] &
adat$daytype==unique(adat$daytype)[d] &
adat$species==unique(adat$species)[s],]
# square rooting varience here to get a SD to keep things in the same terms as the effort threshold above
if(any(unique(z$total.spp.catch)!=0)){
pR=max(unique(z$pReduc)[which(!(b$catch.rate<(z$catch.rate+sqrt(z$catch.rate.var)) & b$catch.rate>(z$catch.rate-sqrt(z$catch.rate.var))))])
if(is.infinite(pR)){
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
species=unique(adat$species)[s],
actual.catch.rate=b$catch.rate,
reduced.catch.rate=NA,
reduced.catch.rate.sd=NA,
pReduc=NA)
thresh.c=rbind(thresh.c,addDat)
}else{
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
species=unique(adat$species)[s],
actual.catch.rate=b$catch.rate,
reduced.catch.rate=z$catch.rate[z$pReduc==pR],
reduced.catch.rate.sd=sqrt(z$catch.rate.var[z$pReduc==pR]),
pReduc=pR)
thresh.c=rbind(thresh.c,addDat)
}
}
}
}
}
}
}
thresh.c=thresh.c[!is.na(thresh.c$wbic),]
## REMEMBER THESE ARE CATCH RATES
# warnings about -inf are fine and dealt with in the loop using the is.infinite() call
thresh.c$month=factor(thresh.c$month, levels = sort(as.numeric(unique(thresh.c$month))), labels = sort(as.numeric(unique(thresh.c$month))))
thresh.c.p=thresh.c[thresh.c$species%in%c("black_crappie","bluegill","largemouth_bass","muskellunge","northern_pike","pumpkinseed","rock_bass","smallmouth_bass","walleye","yellow_perch","brook_trout","brown_trout","lake_trout","rainbow_trout"),] # picking out important species to plot
wknd=ggplot(thresh.c.p[thresh.c.p$daytype=="weekend",])+theme_classic()+
geom_bar(aes(x=pReduc,fill=month),position = "dodge")+
scale_fill_viridis_d()+
facet_wrap(~species, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Month")+
theme(legend.position = "bottom")
wkdy=ggplot(thresh.c.p[thresh.c.p$daytype=="weekday",])+theme_classic()+
geom_bar(aes(x=pReduc,fill=month),position = "dodge")+
scale_fill_viridis_d()+
facet_wrap(~species, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Month")+
theme(legend.position = "bottom")
wknd
wkdy
# grouping across month
annualThresh.c=thresh.c.p%>%
group_by(wbic,year,daytype, survey.seq.no, species)%>%
summarise(actualcatch.rate=sum(as.numeric(actual.catch.rate)),
reduced.catch.rate=sum(as.numeric(reduced.catch.rate),na.rm = T),
reduced.catch.rate.sd=sd(as.numeric(reduced.catch.rate.sd),na.rm = T),
meanPR=mean(as.numeric(pReduc),na.rm=T))
ggplot(annualThresh.c)+theme_classic()+
geom_density(aes(x=meanPR,fill=daytype),alpha=0.2)+
facet_wrap(~species, scales = "free")+
scale_fill_viridis_d()+
labs(x="Mean % of Data Removed", y="Density",fill="Day Type")
# threshold loop for harvest
survs=unique(ttrHarv$survey.seq.no[!is.na(ttrHarv$survey.seq.no)])
thresh.h=data.frame(wbic=NA,
year=NA,
month=NA,
daytype=NA,
survey.seq.no=NA,
species=NA,
actual.total.harvest=NA,
reduced.total.harvest=NA,
reduced.harvest.sd=NA,
pReduc=NA)
for(i in 1:length(survs)){
tdat=ttrHarv[ttrHarv$survey.seq.no==survs[i],]
adat=charv[charv$survey.seq.no==survs[i],]
for(y in 1:length(unique(adat$year))){
for(m in 1:length(unique(adat$month))){
for(d in 1:length(unique(adat$daytype))){
for(s in 1:length(unique(adat$species))){
z=tdat[tdat$year==unique(adat$year)[y] &
tdat$month==unique(adat$month)[m] &
tdat$daytype==unique(adat$daytype)[d] &
tdat$species==unique(adat$species)[s],]
b=adat[adat$year==unique(adat$year)[y] &
adat$month==unique(adat$month)[m] &
adat$daytype==unique(adat$daytype)[d] &
adat$species==unique(adat$species)[s],]
# square rooting varience here to get a SD to keep things in the same terms as the effort threshold above
if(any(unique(z$total.harvest)!=0)){
pR=max(unique(z$pReduc)[which(!(b$total.harvest<(z$total.harvest+sqrt(z$harvest.var)) & b$total.harvest>(z$total.harvest-sqrt(z$harvest.var))))])
if(is.infinite(pR)){
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
species=unique(adat$species)[s],
actual.total.harvest=b$total.harvest,
reduced.total.harvest=NA,
reduced.harvest.sd=NA,
pReduc=NA)
thresh.h=rbind(thresh.h,addDat)
}else{
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
species=unique(adat$species)[s],
actual.total.harvest=b$total.harvest,
reduced.total.harvest=z$total.harvest[z$pReduc==pR],
reduced.harvest.sd=sqrt(z$harvest.var[z$pReduc==pR]),
pReduc=pR)
thresh.h=rbind(thresh.h,addDat)
}
}
}
}
}
}
}
thresh.h=thresh.h[!is.na(thresh.h$wbic),]
# warnings about -inf are fine and dealt with in the loop using the is.infinite() call
thresh.h$month=factor(thresh.h$month, levels = sort(as.numeric(unique(thresh.h$month))), labels = sort(as.numeric(unique(thresh.h$month))))
thresh.h.p=thresh.h[thresh.h$species%in%c("black_crappie","bluegill","largemouth_bass","muskellunge","northern_pike","pumpkinseed","rock_bass","smallmouth_bass","walleye","yellow_perch","brook_trout","brown_trout","lake_trout","rainbow_trout"),] # picking out important species to plot
wknd=ggplot(thresh.h.p[thresh.h.p$daytype=="weekend",])+theme_classic()+
geom_bar(aes(x=pReduc,fill=month),position = "dodge")+
scale_fill_viridis_d()+
facet_wrap(~species, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Month")+
theme(legend.position = "bottom")
wkdy=ggplot(thresh.h.p[thresh.h.p$daytype=="weekday",])+theme_classic()+
geom_bar(aes(x=pReduc,fill=month),position = "dodge")+
scale_fill_viridis_d()+
facet_wrap(~species, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Month")+
theme(legend.position = "bottom")
wknd
wkdy
# grouping across month
annualThresh.h=thresh.h.p%>%
group_by(wbic,year,daytype, survey.seq.no, species)%>%
summarise(actual.total.harvest=sum(as.numeric(actual.total.harvest)),
reduced.total.harvest=sum(as.numeric(reduced.total.harvest),na.rm = T),
reduced.harvest.sd=sd(as.numeric(reduced.harvest.sd),na.rm = T),
meanPR=mean(as.numeric(pReduc),na.rm=T))
ggplot(annualThresh.h)+theme_classic()+
geom_density(aes(x=meanPR,fill=daytype),alpha=0.2)+
facet_wrap(~species, scales = "free")+
scale_fill_viridis_d()+
labs(x="Mean % of Data Removed", y="Density",fill="Day Type")
# threshold loop for harvest rate
survs=unique(ttrHarv$survey.seq.no[!is.na(ttrHarv$survey.seq.no)])
thresh.hr=data.frame(wbic=NA,
year=NA,
month=NA,
daytype=NA,
survey.seq.no=NA,
species=NA,
actual.harvest.rate=NA,
reduced.harvest.rate=NA,
reduced.harvest.rate.sd=NA,
pReduc=NA)
for(i in 1:length(survs)){
tdat=ttrHarv[ttrHarv$survey.seq.no==survs[i],]
adat=charv[charv$survey.seq.no==survs[i],]
for(y in 1:length(unique(adat$year))){
for(m in 1:length(unique(adat$month))){
for(d in 1:length(unique(adat$daytype))){
for(s in 1:length(unique(adat$species))){
z=tdat[tdat$year==unique(adat$year)[y] &
tdat$month==unique(adat$month)[m] &
tdat$daytype==unique(adat$daytype)[d] &
tdat$species==unique(adat$species)[s],]
b=adat[adat$year==unique(adat$year)[y] &
adat$month==unique(adat$month)[m] &
adat$daytype==unique(adat$daytype)[d] &
adat$species==unique(adat$species)[s],]
# square rooting varience here to get a SD to keep things in the same terms as the effort threshold above
if(any(unique(z$harvest.rate)!=0)){
pR=max(unique(z$pReduc)[which(!(b$harvest.rate<(z$harvest.rate+sqrt(z$harvest.rate.var)) & b$harvest.rate>(z$harvest.rate-sqrt(z$harvest.rate.var))))])
if(is.infinite(pR)){
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
species=unique(adat$species)[s],
actual.harvest.rate=b$harvest.rate,
reduced.harvest.rate=NA,
reduced.harvest.sd=NA,
pReduc=NA)
thresh.hr=rbind(thresh.hr,addDat)
}else{
addDat=c(wbic=unique(z$wbic),
year=unique(z$year),
month=unique(z$month),
daytype=unique(z$daytype),
survey.seq.no=survs[i],
species=unique(adat$species)[s],
actual.harvest.rate=b$harvest.rate,
reduced.harvest.rate=z$harvest.rate[z$pReduc==pR],
reduced.harvest.sd=sqrt(z$harvest.rate.var[z$pReduc==pR]),
pReduc=pR)
thresh.hr=rbind(thresh.hr,addDat)
}
}
}
}
}
}
}
thresh.hr=thresh.hr[!is.na(thresh.hr$wbic),]
# warnings about -inf are fine and dealt with in the loop using the is.infinite() call
thresh.hr$month=factor(thresh.hr$month, levels = sort(as.numeric(unique(thresh.hr$month))), labels = sort(as.numeric(unique(thresh.hr$month))))
thresh.hr.p=thresh.hr[thresh.hr$species%in%c("black_crappie","bluegill","largemouth_bass","muskellunge","northern_pike","pumpkinseed","rock_bass","smallmouth_bass","walleye","yellow_perch","brook_trout","brown_trout","lake_trout","rainbow_trout"),] # picking out important species to plot
wknd=ggplot(thresh.hr.p[thresh.hr.p$daytype=="weekend",])+theme_classic()+
geom_bar(aes(x=pReduc,fill=month),position = "dodge")+
scale_fill_viridis_d()+
facet_wrap(~species, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Month")+
theme(legend.position = "bottom")
wkdy=ggplot(thresh.hr.p[thresh.hr.p$daytype=="weekday",])+theme_classic()+
geom_bar(aes(x=pReduc,fill=month),position = "dodge")+
scale_fill_viridis_d()+
facet_wrap(~species, scales = "free")+
labs(x="Proportion of Data Removed", fill= "Month")+
theme(legend.position = "bottom")
wknd
wkdy
# grouping across month
annualthresh.hr=thresh.hr.p%>%
group_by(wbic,year,daytype, survey.seq.no, species)%>%
summarise(actual.harvest.rate=sum(as.numeric(actual.harvest.rate)),
reduced.harvest.rate=sum(as.numeric(reduced.harvest.rate),na.rm = T),
reduced.harvest.rate.sd=sd(as.numeric(reduced.harvest.rate.sd),na.rm = T),
meanPR=mean(as.numeric(pReduc),na.rm=T))
ggplot(annualthresh.hr)+theme_classic()+
geom_density(aes(x=meanPR,fill=daytype),alpha=0.2)+
facet_wrap(~species, scales = "free")+
scale_fill_viridis_d()+
labs(x="Mean % of Data Removed", y="Density",fill="Day Type")
