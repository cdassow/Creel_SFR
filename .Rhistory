eff.25wd=eff.25wd%>%
left_join(lchar[,c(1,15)])%>%
mutate(annual.eff.acre=total.effort/lake.area)
wd25=ifish.25wd%>%
group_by(wbic, year,survey.seq.no,survey.begin.date,survey.end.date, mark.found,month,daytype)%>%
summarise(nfish=sum(fish.count)) # number of fish of each mark typed returned in that creel
wd25=wd25%>% # now throwing out mark type and just taking overall number of marks recapped that month for that survey.
group_by(wbic, year, survey.seq.no, survey.begin.date, survey.end.date,month,daytype)%>%
summarise(n.marks.recapped=sum(nfish[!is.na(mark.found)]),
totalFishExamined=sum(nfish))
# spp.harvest is the column that has the estimate of the harvest for that species in that strata
harvestEstimates.25wd=iharv.25wd%>%
filter(species.code=="X22")%>%
select(year,wbic,survey.seq.no, month, daytype,spp.harvest,harvest,total.harvest,total.spp.harvest)
# combining harvest estimates with marked proportion estimate to get total number of marks harvested
markHarvEst.25wd=wd25%>%
left_join(harvestEstimates.25wd)%>%
mutate(markHarvEstimate=(n.marks.recapped/totalFishExamined)*spp.harvest)
ang.exp.25wd=markHarvEst.25wd%>%
left_join(fdat, by=c("wbic"="WBIC","year"="Survey.Year"))%>%
mutate(exp.rate=markHarvEstimate/nFN.marked)
# Throwing out NA u's and those >1 (NAs from lack of walleye harvest per strata or missing FN marks, >1's is 6 observations where # marks in creel exceeds # marks at large)
ang.exp.25wd=ang.exp.25wd[!is.na(ang.exp.25wd$exp.rate) & ang.exp.25wd$exp.rate<1.0,]
# creating survey-level effort estimates
ang.exp.25wd=ang.exp.25wd%>%
group_by(survey.seq.no)%>%
summarise(meanU=mean(exp.rate,na.rm = T),
exp.rate.sd=sd(exp.rate,na.rm = T))
###### 50% WEEKDAYS ####
rm.fish.seq.no=NA
rm.visit.fish.seq.no=NA
ifish.surv=unique(ifish$survey.seq.no)
set.seed(3)
for(i in 1:length(ifish.surv)){ # survey loop
full=ifish[ifish$survey.seq.no==ifish.surv[i] & ifish$daytype=="weekday",]
ms=unique(full$month)
if(nrow(full)>0){
for(m in 1:length(ms)){ # month loop
visits=unique(full$visit.fish.seq.no[full$month==ms[m]])
visit.rm=visits[c(round(runif(round(0.50*length(visits)),min=1,max = length(visits))))]
t.rm=full$fish.data.seq.no[full$visit.fish.seq.no%in%visit.rm]# fish seq nos to remove that associated with the vist seq nos selected for removal
rm.visit.fish.seq.no=c(rm.visit.fish.seq.no,visit.rm) # visit fish seq nos to use to reduce the interview, count, and fish data needed to get harvest estimates
rm.fish.seq.no=c(rm.fish.seq.no,t.rm) # vector of fish to remove from individual fish data
}
}
}
ifish.50wd=ifish[!(ifish$fish.data.seq.no%in%rm.fish.seq.no),] # reduced individual fish data
iint.50wd=cint%>%
filter(wbic%in%ctwiWBIC.creel & !(visit.fish.seq.no%in%rm.visit.fish.seq.no)) # reduced interview data
icou.50wd=ccou%>%
filter(wbic%in%ctwiWBIC.creel & !(visit.fish.seq.no%in%rm.visit.fish.seq.no)) # reduced count data
ifishAg.50wd=cfish%>%
filter(wbic%in%ctwiWBIC.creel & !(visit.fish.seq.no%in%rm.visit.fish.seq.no)) # reduced aggregate fish data
iharv.50wd=calc_creel_harvest(creel_count_data = icou.50wd,
creel_int_data = iint.50wd,
creel_fish_data = ifishAg.50wd) # harvest estimates from the reduced data
eff.50wd=calc_creel_effort(creel_count_data = icou.50wd, creel_int_data = iint.50wd)
eff.50wd=eff.50wd%>%
left_join(lchar[,c(1,15)])%>%
mutate(annual.eff.acre=total.effort/lake.area)
wd50=ifish.50wd%>%
group_by(wbic, year,survey.seq.no,survey.begin.date,survey.end.date, mark.found,month,daytype)%>%
summarise(nfish=sum(fish.count)) # number of fish of each mark typed returned in that creel
wd50=wd50%>% # now throwing out mark type and just taking overall number of marks recapped that month for that survey.
group_by(wbic, year, survey.seq.no, survey.begin.date, survey.end.date,month,daytype)%>%
summarise(n.marks.recapped=sum(nfish[!is.na(mark.found)]),
totalFishExamined=sum(nfish))
# spp.harvest is the column that has the estimate of the harvest for that species in that strata
harvestEstimates.50wd=iharv.50wd%>%
filter(species.code=="X22")%>%
select(year,wbic,survey.seq.no, month, daytype,spp.harvest,harvest,total.harvest,total.spp.harvest)
# combining harvest estimates with marked proportion estimate to get total number of marks harvested
markHarvEst.50wd=wd50%>%
left_join(harvestEstimates.50wd)%>%
mutate(markHarvEstimate=(n.marks.recapped/totalFishExamined)*spp.harvest)
ang.exp.50wd=markHarvEst.50wd%>%
left_join(fdat, by=c("wbic"="WBIC","year"="Survey.Year"))%>%
mutate(exp.rate=markHarvEstimate/nFN.marked)
# Throwing out NA u's and those >1 (NAs from lack of walleye harvest per strata or missing FN marks, >1's is 6 observations where # marks in creel exceeds # marks at large)
ang.exp.50wd=ang.exp.50wd[!is.na(ang.exp.50wd$exp.rate) & ang.exp.50wd$exp.rate<1.0,]
# creating survey-level effort estimates
ang.exp.50wd=ang.exp.50wd%>%
group_by(survey.seq.no)%>%
summarise(meanU=mean(exp.rate,na.rm = T),
exp.rate.sd=sd(exp.rate,na.rm = T))
###### 50% WEEKENDS ####
rm.fish.seq.no=NA
rm.visit.fish.seq.no=NA
ifish.surv=unique(ifish$survey.seq.no)
set.seed(3)
for(i in 1:length(ifish.surv)){ # survey loop
full=ifish[ifish$survey.seq.no==ifish.surv[i] & ifish$daytype=="weekend",]
ms=unique(full$month)
if(nrow(full)>0){
for(m in 1:length(ms)){ # month loop
visits=unique(full$visit.fish.seq.no[full$month==ms[m]])
visit.rm=visits[c(round(runif(round(0.50*length(visits)),min=1,max = length(visits))))]
t.rm=full$fish.data.seq.no[full$visit.fish.seq.no%in%visit.rm]# fish seq nos to remove that associated with the vist seq nos selected for removal
rm.visit.fish.seq.no=c(rm.visit.fish.seq.no,visit.rm) # visit fish seq nos to use to reduce the interview, count, and fish data needed to get harvest estimates
rm.fish.seq.no=c(rm.fish.seq.no,t.rm) # vector of fish to remove from individual fish data
}
}
}
ifish.50we=ifish[!(ifish$fish.data.seq.no%in%rm.fish.seq.no),] # reduced individual fish data
iint.50we=cint%>%
filter(wbic%in%ctwiWBIC.creel & !(visit.fish.seq.no%in%rm.visit.fish.seq.no)) # reduced interview data
icou.50we=ccou%>%
filter(wbic%in%ctwiWBIC.creel & !(visit.fish.seq.no%in%rm.visit.fish.seq.no)) # reduced count data
ifishAg.50we=cfish%>%
filter(wbic%in%ctwiWBIC.creel & !(visit.fish.seq.no%in%rm.visit.fish.seq.no)) # reduced aggregate fish data
iharv.50we=calc_creel_harvest(creel_count_data = icou.50we,
creel_int_data = iint.50we,
creel_fish_data = ifishAg.50we) # harvest estimates from the reduced data
eff.50we=calc_creel_effort(creel_count_data = icou.50we, creel_int_data = iint.50we)
eff.50we=eff.50we%>%
left_join(lchar[,c(1,15)])%>%
mutate(annual.eff.acre=total.effort/lake.area)
we50=ifish.50we%>%
group_by(wbic, year,survey.seq.no,survey.begin.date,survey.end.date, mark.found,month,daytype)%>%
summarise(nfish=sum(fish.count)) # number of fish of each mark typed returned in that creel
we50=we50%>% # now throwing out mark type and just taking overall number of marks recapped that month for that survey.
group_by(wbic, year, survey.seq.no, survey.begin.date, survey.end.date,month,daytype)%>%
summarise(n.marks.recapped=sum(nfish[!is.na(mark.found)]),
totalFishExamined=sum(nfish))
# spp.harvest is the column that has the estimate of the harvest for that species in that strata
harvestEstimates.50we=iharv.50we%>%
filter(species.code=="X22")%>%
select(year,wbic,survey.seq.no, month, daytype,spp.harvest,harvest,total.harvest,total.spp.harvest)
# combining harvest estimates with marked proportion estimate to get total number of marks harvested
markHarvEst.50we=we50%>%
left_join(harvestEstimates.50we)%>%
mutate(markHarvEstimate=(n.marks.recapped/totalFishExamined)*spp.harvest)
ang.exp.50we=markHarvEst.50we%>%
left_join(fdat, by=c("wbic"="WBIC","year"="Survey.Year"))%>%
mutate(exp.rate=markHarvEstimate/nFN.marked)
# Throwing out NA u's and those >1 (NAs from lack of walleye harvest per strata or missing FN marks, >1's is 6 observations where # marks in creel exceeds # marks at large)
ang.exp.50we=ang.exp.50we[!is.na(ang.exp.50we$exp.rate) & ang.exp.50we$exp.rate<1.0,]
# creating survey-level effort estimates
ang.exp.50we=ang.exp.50we%>%
group_by(survey.seq.no)%>%
summarise(meanU=mean(exp.rate,na.rm = T),
exp.rate.sd=sd(exp.rate,na.rm = T))
# plot of effort by month
ceff.ct$plot.month=month(ceff.ct$month,label = T)
p1=ggplot(ceff.ct)+theme_classic()+
geom_boxplot(aes(y=ceff.ct$annual.eff.acre, x=plot.month), fill="grey")+
geom_hline(yintercept = mean(ceff.ct$annual.eff.acre, na.rm = T), color="red")+
labs(y=" Annual Effort per Acre", x="Month")
# plot of effort by month - logged
p2=ggplot(ceff.ct)+theme_classic()+
geom_boxplot(aes(y=log(ceff.ct$annual.eff.acre), x=plot.month), fill="grey")+
geom_hline(yintercept = log(mean(ceff.ct$annual.eff.acre)), color="red")+ # setting this manually since the 0 exp rates mess up the logging here
labs(y="Log(Annual Effort per Acre)", x="Month")
ggarrange(p1,p2,nrow = 1,ncol=2,labels = 'auto')
# creating survey-level effort for the actual data
eff.surv.a=ceff.ct%>%
group_by(survey.seq.no)%>%
summarise(total.eff=sum(annual.eff.acre,na.rm = T))
eff.surv.nw=eff.nw%>%
group_by(survey.seq.no)%>%
summarise(total.eff=sum(annual.eff.acre,na.rm = T))
eff.surv.ma=eff.ma%>%
group_by(survey.seq.no)%>%
summarise(total.eff=sum(annual.eff.acre,na.rm = T))
eff.surv.25wd=eff.25wd%>%
group_by(survey.seq.no)%>%
summarise(total.eff=sum(annual.eff.acre,na.rm = T))
eff.surv.50wd=eff.50wd%>%
group_by(survey.seq.no)%>%
summarise(total.eff=sum(annual.eff.acre,na.rm = T))
eff.surv.50we=eff.50we%>%
group_by(survey.seq.no)%>%
summarise(total.eff=sum(annual.eff.acre,na.rm = T))
# combining actual and reduced dataframes into one big one for plotting
ttrExp=rbind(cbind(eff.surv.a,treat=rep("actual",nrow(eff.surv.a))),
cbind(eff.surv.nw, treat=rep("noWinter",nrow(eff.surv.nw))),
cbind(eff.surv.ma, treat=rep("mayAug",nrow(eff.surv.ma))),
cbind(eff.surv.25wd, treat=rep("wd25",nrow(eff.surv.25wd))),
cbind(eff.surv.50wd, treat=rep("wd50",nrow(eff.surv.50wd))),
cbind(eff.surv.50we, treat=rep("we50",nrow(eff.surv.50we))))
ggplot(ttrExp)+theme_classic()+
geom_density(aes(x=log(total.eff), fill=treat),alpha=0.2)+
labs(x="Log(Annual Effort)", y="Density", fill="Scenario")
# data is non normally distributed, effort is continuous and greater than 0, consider gamma or lognormal distribution for modeling
# one likelihood to estimate parms for using the 6 different treatments
# creating data frame to model with effort estimates
#removing 0s since they can't be logged and if I were to make them a small number they would throw off the data and make it bimodal which would probably mean switching to a gamma distribution to model the data. There are 8 0's accounting for 1% of the data. I'm going to operate under the assumption that if a survey gives a 0 effort estimate with the full survey, then efs collecting less data isn't going to change that number.
zeros.actual=sum(ttrExp$total.eff[ttrExp$treat=="actual"]==0)
zeros.nw=sum(ttrExp$total.eff[ttrExp$treat=="noWinter"]==0)
zeros.ma=sum(ttrExp$total.eff[ttrExp$treat=="mayAug"]==0)
zeros.wd25=sum(ttrExp$total.eff[ttrExp$treat=="wd25"]==0)
zeros.wd50=sum(ttrExp$total.eff[ttrExp$treat=="wd50"]==0)
zeros.we50=sum(ttrExp$total.eff[ttrExp$treat=="we50"]==0)
Ztab=data.frame(Scenario=c("Actual","No Winter","May-August","25% Weekday Reduction","50% Weekday Reduction","50% Weekend Reduction"),
Zeros=c(zeros.actual,zeros.nw,zeros.ma,zeros.wd25,zeros.wd50,zeros.we50))
kable(Ztab,
format='latex',
caption="Table of the number of surveys with effort estimates equal to 0 for each data scenario.")
# removing 0s here as described in the text.
modDat=ttrExp[ttrExp$total.eff!=0,]
#### ACTUAL ####
effLL.a=function(param){
alpha=param[1]
beta=param[2]
efs=rlnorm(nrow(modDat[modDat$treat=="actual",]),meanlog = alpha, sdlog = beta)
ll=dlnorm(modDat$total.eff[modDat$treat=="actual"], meanlog = mean(log(efs)), sdlog = sd(log(efs)), log = T)
return(sum(ll))
}
prior=createTruncatedNormalPrior(mean=c(mean(log(modDat$total.eff[modDat$treat=="actual"])),sd(log(modDat$total.eff[modDat$treat=="actual"]))),
sd=c(1,1),
lower = c(-15,0),
upper = c(15,5))
setup.actual=createBayesianSetup(effLL.a, prior = prior)
settings=list(iterations=10000, nrChains=3, message=F, burnin=5000)
set.seed(10)
eff.actual=runMCMC(bayesianSetup = setup.actual, sampler = "DEzs", settings = settings) # takes about 10 seconds
#### NW ####
effLL.nw=function(param){
alpha=param[1]
beta=param[2]
efs=rlnorm(nrow(modDat[modDat$treat=="noWinter",]),meanlog = alpha, sdlog = beta)
ll=dlnorm(modDat$total.eff[modDat$treat=="noWinter"], meanlog = mean(log(efs)), sdlog = sd(log(efs)), log = T)
return(sum(ll))
}
prior=createTruncatedNormalPrior(mean=c(mean(log(modDat$total.eff[modDat$treat=="noWinter"])),sd(log(modDat$total.eff[modDat$treat=="noWinter"]))),
sd=c(1,1),
lower = c(-15,0),
upper = c(15,5))
setup.nw=createBayesianSetup(effLL.nw, prior = prior)
settings=list(iterations=10000, nrChains=3, message=F, burnin=5000)
set.seed(10)
eff.nw=runMCMC(bayesianSetup = setup.nw, sampler = "DEzs", settings = settings)
#### MA ####
effLL.ma=function(param){
alpha=param[1]
beta=param[2]
efs=rlnorm(nrow(modDat[modDat$treat=="mayAug",]),meanlog = alpha, sdlog = beta)
ll=dlnorm(modDat$total.eff[modDat$treat=="mayAug"], meanlog = mean(log(efs)), sdlog = sd(log(efs)), log = T)
return(sum(ll))
}
prior=createTruncatedNormalPrior(mean=c(mean(log(modDat$total.eff[modDat$treat=="mayAug"])),sd(log(modDat$total.eff[modDat$treat=="mayAug"]))),
sd=c(1,1),
lower = c(-15,0),
upper = c(15,5))
setup.ma=createBayesianSetup(effLL.ma, prior = prior)
settings=list(iterations=10000, nrChains=3, message=F, burnin=5000)
set.seed(10)
eff.ma=runMCMC(bayesianSetup = setup.ma, sampler = "DEzs", settings = settings)
#### WD25 ####
effLL.wd25=function(param){
alpha=param[1]
beta=param[2]
efs=rlnorm(nrow(modDat[modDat$treat=="wd25",]),meanlog = alpha, sdlog = beta)
ll=dlnorm(modDat$total.eff[modDat$treat=="wd25"], meanlog = mean(log(efs)), sdlog = sd(log(efs)), log = T)
return(sum(ll))
}
prior=createTruncatedNormalPrior(mean=c(mean(log(modDat$total.eff[modDat$treat=="wd25"])),sd(log(modDat$total.eff[modDat$treat=="wd25"]))),
sd=c(1,1),
lower = c(-15,0),
upper = c(15,5))
setup.wd25=createBayesianSetup(effLL.wd25, prior = prior)
settings=list(iterations=10000, nrChains=3, message=F, burnin=5000)
set.seed(10)
eff.25wd=runMCMC(bayesianSetup = setup.wd25, sampler = "DEzs", settings = settings)
#### WD50 ####
effLL.wd50=function(param){
alpha=param[1]
beta=param[2]
efs=rlnorm(nrow(modDat[modDat$treat=="wd50",]),meanlog = alpha, sdlog = beta)
ll=dlnorm(modDat$total.eff[modDat$treat=="wd50"], meanlog = mean(log(efs)), sdlog = sd(log(efs)), log = T)
return(sum(ll))
}
prior=createTruncatedNormalPrior(mean=c(mean(log(modDat$total.eff[modDat$treat=="wd50"])),sd(log(modDat$total.eff[modDat$treat=="wd50"]))),
sd=c(1,1),
lower = c(-15,0),
upper = c(15,5))
setup.wd50=createBayesianSetup(effLL.wd50, prior = prior)
settings=list(iterations=10000, nrChains=3, message=F, burnin=5000)
set.seed(10)
eff.50wd=runMCMC(bayesianSetup = setup.wd50, sampler = "DEzs", settings = settings)
#### WE50 ####
effLL.we50=function(param){
alpha=param[1]
beta=param[2]
efs=rlnorm(nrow(modDat[modDat$treat=="we50",]),meanlog = alpha, sdlog = beta)
ll=dlnorm(modDat$total.eff[modDat$treat=="we50"], meanlog = mean(log(efs)), sdlog = sd(log(efs)), log = T)
return(sum(ll))
}
prior=createTruncatedNormalPrior(mean=c(mean(log(modDat$total.eff[modDat$treat=="we50"])),sd(log(modDat$total.eff[modDat$treat=="we50"]))),
sd=c(1,1),
lower = c(-15,0),
upper = c(15,5))
setup.we50=createBayesianSetup(effLL.we50, prior = prior)
settings=list(iterations=10000, nrChains=3, message=F, burnin=5000)
set.seed(10)
eff.50we=runMCMC(bayesianSetup = setup.we50, sampler = "DEzs", settings = settings)
# looking to see if parm estimates produce data that visually at least looks like the observed data for that scenario
pars.a=getSample(eff.actual)
pars.nw=getSample(eff.nw)
pars.ma=getSample(eff.ma)
pars.wd25=getSample(eff.25wd)
pars.wd50=getSample(eff.50wd)
pars.we50=getSample(eff.50we)
set.seed(3)
aComp=data.frame(eff.acre=c(modDat$total.eff[modDat$treat=="actual"],rlnorm(n=length(modDat$total.eff[modDat$treat=="actual"]),
meanlog = median(pars.a[,1]),
sdlog = median(pars.a[,2]))),
treat=c(rep("observed",length(modDat$total.eff[modDat$treat=="actual"])),rep("pred",length(modDat$total.eff[modDat$treat=="actual"]))))
set.seed(3)
nwComp=data.frame(eff.acre=c(modDat$total.eff[modDat$treat=="noWinter"],rlnorm(n=length(modDat$total.eff[modDat$treat=="noWinter"]),
meanlog = median(pars.nw[,1]),
sdlog = median(pars.nw[,2]))),
treat=c(rep("observed",length(modDat$total.eff[modDat$treat=="noWinter"])),rep("pred",length(modDat$total.eff[modDat$treat=="noWinter"]))))
set.seed(3)
maComp=data.frame(eff.acre=c(modDat$total.eff[modDat$treat=="mayAug"],rlnorm(n=length(modDat$total.eff[modDat$treat=="mayAug"]),
meanlog = median(pars.ma[,1]),
sdlog = median(pars.ma[,2]))),
treat=c(rep("observed",length(modDat$total.eff[modDat$treat=="mayAug"])),rep("pred",length(modDat$total.eff[modDat$treat=="mayAug"]))))
set.seed(3)
wd25Comp=data.frame(eff.acre=c(modDat$total.eff[modDat$treat=="wd25"],rlnorm(n=length(modDat$total.eff[modDat$treat=="wd25"]),
meanlog = median(pars.wd25[,1]),
sdlog = median(pars.wd25[,2]))),
treat=c(rep("observed",length(modDat$total.eff[modDat$treat=="wd25"])),rep("pred",length(modDat$total.eff[modDat$treat=="wd25"]))))
set.seed(3)
wd50Comp=data.frame(eff.acre=c(modDat$total.eff[modDat$treat=="wd50"],rlnorm(n=length(modDat$total.eff[modDat$treat=="wd50"]),
meanlog = median(pars.wd50[,1]),
sdlog = median(pars.wd50[,2]))),
treat=c(rep("observed",length(modDat$total.eff[modDat$treat=="wd50"])),rep("pred",length(modDat$total.eff[modDat$treat=="wd50"]))))
set.seed(3)
we50Comp=data.frame(eff.acre=c(modDat$total.eff[modDat$treat=="we50"],rlnorm(n=length(modDat$total.eff[modDat$treat=="we50"]),
meanlog = median(pars.we50[,1]),
sdlog = median(pars.we50[,2]))),
treat=c(rep("observed",length(modDat$total.eff[modDat$treat=="we50"])),rep("pred",length(modDat$total.eff[modDat$treat=="we50"]))))
a.p=ggplot(aComp)+theme_classic()+
geom_density(aes(x=log(eff.acre),fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Log(Annual Effort per Acre)", y="Density", title = "Actual", fill=element_blank())
nw.p=ggplot(nwComp)+theme_classic()+
geom_density(aes(x=log(eff.acre),fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Log(Annual Effort per Acre)", y="Density", title = "No Winter Data \n(April - October)", fill=element_blank())
ma.p=ggplot(maComp)+theme_classic()+
geom_density(aes(x=log(eff.acre),fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Log(Annual Effort per Acre)", y="Density", title = "May - August \nData Only", fill=element_blank())
wd25.p=ggplot(wd25Comp)+theme_classic()+
geom_density(aes(x=log(eff.acre),fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Log(Annual Effort per Acre)", y="Density", title = "25% of Weekday \nCreel Visits/Month \nRemoved", fill=element_blank())
wd50.p=ggplot(wd25Comp)+theme_classic()+
geom_density(aes(x=log(eff.acre),fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Log(Annual Effort per Acre)", y="Density", title = "50% of Weekday \nCreel Visits/Month \nRemoved", fill=element_blank())
we50.p=ggplot(we50Comp)+theme_classic()+
geom_density(aes(x=log(eff.acre),fill=treat),alpha=0.2)+
scale_fill_viridis_d()+labs(x="Log(Annual Effort per Acre)", y="Density", title = "50% of Weekdend \nCreel Visits/Month \nRemoved", fill=element_blank())
ggarrange(a.p,nw.p,ma.p,wd25.p,wd50.p,we50.p, common.legend = T)
pars.all=bind_rows(as.data.frame(pars.a),
as.data.frame(pars.nw),
as.data.frame(pars.ma),
as.data.frame(pars.wd25),
as.data.frame(pars.wd50),
as.data.frame(pars.we50))%>%
mutate(treat=c(rep('actual',nrow(pars.a)),
rep('nw',nrow(pars.nw)),
rep('ma',nrow(pars.ma)),
rep('wd25',nrow(pars.wd25)),
rep('wd50',nrow(pars.wd50)),
rep('we50',nrow(pars.we50))),
metric='effort')
saveRDS(pars.all, 'allPars_effort.RData')
p.exp=readRDS('allPars_explR.RData')
p.harvR=readRDS('allPars_harvR.RData')
p.harv=readRDS('allPars_harv.RData')
p.catch=readRDS('allPars_catch.RData')
p.eff=readRDS('allPars_effort.RData')
head(p.eff)
colnames(p.eff)
p.all=bind_rows(p.exp,
p.harvR,
p.harv,
p.catch,
p.eff)%>%
rename(meanLogpar='par 1',
sdLogpar='par 2')%>%
group_by(metric,treat)%>%
summarise(meanLog=median(meanLogpar),
meanLog.lcl=quantile(meanLogpar,probs=0.025),
meanLog.ucl=quantile(meanLogpar,probs=0.975),
sdLog=median(sdLogpar),
sdLog.lcl=quantile(sdLogpar,probs=0.025),
sdLog.ucl=quantile(sdLogpar,probs=0.975))
View(p.all)
head(p.all)
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
facet_wrap(~metric)
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
facet_wrap(~metric, scales = 'free')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
facet_wrap(~metric, scales = 'free')+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=sdLog,  ymin=sdLog.lcl, ymax=sdLog.ucl))+
facet_wrap(~metric, scales = 'free')+
labs(y='Stan.Dev. of Lognormal Distribution', x='Data Set')
metNames=c('catch'='Catch (walleye/acre)',
'effort'='Effort (hours/acre)',
'expR'='Exploitation Rate',
'harv'='Harvest (wallye/acre)',
'harvR'='Harvest Rate')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(values='Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed')+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(values=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45,hjust1))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45,hjust=1))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45, hjust=0))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=sdLog,  ymin=sdLog.lcl, ymax=sdLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45, hjust=0))+
facet_wrap(~metric, scales = 'free')+
labs(y='Stan.Dev. of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=sdLog,  ymin=sdLog.lcl, ymax=sdLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45, hjust=0))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Stan.Dev. of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45, hjust=0))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = 45, hjust=0))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
180+45
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = 225, hjust=0))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45, hjust=-1))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = -45, hjust=0))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = 45))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=meanLog,  ymin=meanLog.lcl, ymax=meanLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = 45, hjust=1))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Mean of Lognormal Distribution', x='Data Set')
ggplot(p.all)+theme_classic()+
geom_pointrange(aes(x=treat, y=sdLog,  ymin=sdLog.lcl, ymax=sdLog.ucl))+
scale_x_discrete(label=c('Actual','May-August','No Winter','25% Weekday Removed','50% Weekday Removed','50% Weekend Removed'))+
theme(axis.text.x = element_text(angle = 45, hjust=1))+
facet_wrap(~metric, scales = 'free', labeller = as_labeller(metNames))+
labs(y='Stan.Dev. of Lognormal Distribution', x='Data Set')
